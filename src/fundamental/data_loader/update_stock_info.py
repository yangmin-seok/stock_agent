import logging
import psycopg2
from psycopg2 import extras
from src.fundamental.data_loader.db_util import get_db_connection, setup_database
from src.fundamental.data_loader.config import DB_CONFIG
import pandas as pd
import numpy as np
import requests
import os
import xml.etree.ElementTree as ET # XML íŒŒì‹±ì„ ìœ„í•´ ì¶”ê°€
from io import BytesIO # contentë¥¼ ë°”ë¡œ íŒŒì‹±í•˜ê¸° ìœ„í•´ ì¶”ê°€
import zipfile  # ğŸ‘ˆ [1. ìˆ˜ì •] zipfile ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸

# ë¡œê¹… ì„¤ì •: ì§„í–‰ ìƒí™©ì„ í„°ë¯¸ë„ì— ì¶œë ¥
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def get_corp_codes_from_dart():
    """
    DART APIë¥¼ í˜¸ì¶œí•˜ì—¬ ëª¨ë“  ê¸°ì—…ì˜ ê³ ìœ ë²ˆí˜¸, ê¸°ì—…ëª…, ì¢…ëª©ì½”ë“œë¥¼ ë°›ì•„ì˜µë‹ˆë‹¤.
    ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    logger.info("ğŸ“ˆ DART APIì—ì„œ ê¸°ì—… ê³ ìœ ë²ˆí˜¸ ëª©ë¡ì„ ìš”ì²­í•©ë‹ˆë‹¤...")
    url = 'https://opendart.fss.or.kr/api/corpCode.xml'
    params = {'crtfc_key': os.environ.get('DART_API_KEY', '')}
    
    try:
        response = requests.get(url, params=params)
        response.raise_for_status() 

        logger.info("ğŸ›°ï¸ API ì‘ë‹µ(ZIP)ì„ ìˆ˜ì‹ í–ˆìŠµë‹ˆë‹¤. ì••ì¶• í•´ì œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")

        xml_content = None # XML ë‚´ìš©ì„ ë‹´ì„ ë³€ìˆ˜

        # â–¼â–¼â–¼ [1. ìˆ˜ì •] ì••ì¶• í•´ì œ ë° XML ë‚´ìš© ì½ê¸° â–¼â–¼â–¼
        with zipfile.ZipFile(BytesIO(response.content)) as z:
            # ZIP íŒŒì¼ ë‚´ì˜ 'CORPCODE.xml' íŒŒì¼ì˜ ë‚´ìš©ì„ ì—½ë‹ˆë‹¤.
            try:
                with z.open('CORPCODE.xml') as f:
                    # XML ë‚´ìš©ì„ ë³€ìˆ˜ë¡œ ì½ì–´ì˜µë‹ˆë‹¤.
                    xml_content = f.read()
            except KeyError:
                logger.error("ZIP íŒŒì¼ ë‚´ì— 'CORPCODE.xml' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return None

        # # â–¼â–¼â–¼ [2. ìˆ˜ì •] ë””ë²„ê¹…ìš© XML íŒŒì¼ ì €ì¥ â–¼â–¼â–¼
        # if xml_content:
        #     # ì½ì–´ì˜¨ XML content(bytes)ë¥¼ .xml íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
        #     debug_filename = 'dart_response_debug.xml'
        #     with open(debug_filename, 'wb') as f:
        #         f.write(xml_content)
        #     logger.info(f"ğŸ ë””ë²„ê¹…ìš© XML íŒŒì¼ ì €ì¥ ì™„ë£Œ: {debug_filename}")
        # else:
        #     # ì´ ê²½ìš°ëŠ” ê±°ì˜ ë°œìƒí•˜ì§€ ì•Šì§€ë§Œ, ë°©ì–´ ì½”ë“œ
        #     logger.error("XML ë‚´ìš©ì„ ì½ì–´ì˜¤ì§€ ëª»í•´ ì €ì¥ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        #     return None

        logger.info("XML íŒŒì‹±ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        tree = ET.parse(BytesIO(xml_content))
        root = tree.getroot()

        # API ì—ëŸ¬ í™•ì¸ (DART APIëŠ” status ì½”ë“œë¡œ ì„±ê³µ ì—¬ë¶€ë¥¼ ì•Œë ¤ì¤Œ)
        status = root.findtext('status')
        message = root.findtext('message')
        
        # ... (ì´í•˜ XML íŒŒì‹± ë° DataFrame ë³€í™˜ ë¡œì§ì€ ë™ì¼) ...
        data_list = []
        for item in root.findall('./list'):
            data_list.append({
                'corp_code': item.findtext('corp_code'),
                'corp_name': item.findtext('corp_name'),
                'stock_code': item.findtext('stock_code').strip() or None,
            })

        if not data_list:
            logger.warning("APIëŠ” ì„±ê³µí–ˆìœ¼ë‚˜ íŒŒì‹±ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None

        df = pd.DataFrame(data_list)
        return df

    except requests.exceptions.RequestException as e:
        logger.error(f"API ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None
    except zipfile.BadZipFile as e: 
        logger.error(f"ZIP íŒŒì¼ ì••ì¶• í•´ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None
    except ET.ParseError as e:
        logger.error(f"XML íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        logger.error(f"ìˆ˜ì‹ ëœ ë°ì´í„° (ì¼ë¶€): {response.content[:200]}...")
        return None

def update_stock_info():
    """
    stock_info í…Œì´ë¸”ì„ DART APIì—ì„œ ë°›ì•„ì˜¨ ìµœì‹  ê¸°ì—… ì •ë³´ë¡œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    """
    
    # DART APIë¡œë¶€í„° ê¸°ì—… ëª©ë¡ DataFrame ê°€ì ¸ì˜¤ê¸°
    corp_code_df = get_corp_codes_from_dart()

    # â–¼â–¼â–¼ [ìˆ˜ì •/ì¶”ê°€ëœ í•µì‹¬ ë¡œì§] â–¼â–¼â–¼
    logger.info("ğŸ¼ DataFrame ì»¬ëŸ¼ëª…ì„ DB ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ë³€ê²½í•©ë‹ˆë‹¤...")
    
    # 1. DART API ì»¬ëŸ¼ëª… -> DB ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë³€ê²½
    df_to_save = corp_code_df.rename(columns={
        'corp_name': 'company_name',
        'stock_code': 'company_code'
    })

    # 2. DB ìŠ¤í‚¤ë§ˆì—ì„œ company_codeê°€ NOT NULLì´ë¯€ë¡œ,
    # stock_codeê°€ ì—†ëŠ”(None) ë¹„ìƒì¥ ê¸°ì—… ë“±ì€ ì œì™¸í•©ë‹ˆë‹¤.
    original_count = len(df_to_save)
    df_to_save = df_to_save.dropna(subset=['company_code'])
    filtered_count = original_count - len(df_to_save)
    if filtered_count > 0:
        logger.info(f"ë¹„ìƒì¥ ê¸°ì—… (company_code=None) {filtered_count}ê±´ì„ ì œì™¸í–ˆìŠµë‹ˆë‹¤.")
    # â–²â–²â–² [ìˆ˜ì •/ì¶”ê°€ëœ í•µì‹¬ ë¡œì§ ë] â–²â–²â–²

    # (DB ì €ì¥ ë¡œì§ ì‹œì‘)
    conn = None

    logger.info("ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ì— ì—°ê²°í•©ë‹ˆë‹¤...")
    conn = get_db_connection(DB_CONFIG)
    logger.info("ğŸ› ï¸ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆë¥¼ ì„¤ì •í•©ë‹ˆë‹¤ (í…Œì´ë¸”ì´ ì—†ëŠ” ê²½ìš° ìƒì„±).")
    setup_database(conn, path='src/fundamental/data_loader/sql/stock_info_schema.sql')
    
    logger.info(f"ğŸ’¾ ì´ {len(df_to_save)}ê°œì˜ ê¸°ì—… ì •ë³´ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥(UPSERT)í•©ë‹ˆë‹¤...")

    # save logic
    df_to_save = df_to_save.replace({np.nan: None}) # Pandas NA -> None
    data_to_dict = df_to_save.to_dict('records')

    if not data_to_dict:
        logger.warning("ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        if conn:
            conn.close()
        return

    # ì´ì œ columnsëŠ” ['corp_code', 'company_name', 'company_code']ê°€ ë©ë‹ˆë‹¤.
    columns = data_to_dict[0].keys()
    cols_str = ", ".join(f'"{col}"' for col in columns)
    placeholders = ", ".join([f"%({col})s" for col in columns])

    # ON CONFLICT ì‹œ ì—…ë°ì´íŠ¸í•  ì»¬ëŸ¼ë“¤ (ê³ ìœ  í‚¤ ì œì™¸)
    # PKì¸ 'corp_code'ë¥¼ ì œì™¸í•œ ì»¬ëŸ¼ë“¤
    update_cols = [col for col in columns if col not in ['corp_code']]
    update_str = ", ".join([f'"{col}" = EXCLUDED."{col}"' for col in update_cols])

    # ìŠ¤í‚¤ë§ˆì˜ PRIMARY KEYì¸ 'corp_code'ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ON CONFLICTë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    sql = f"""
    INSERT INTO stock_info ({cols_str})
    VALUES ({placeholders})
    ON CONFLICT (corp_code) DO UPDATE SET 
        {update_str},
        updated_at = CURRENT_TIMESTAMP; 
    """ # updated_at íƒ€ì„ìŠ¤íƒ¬í”„ë„ ê°±ì‹ í•´ì¤ë‹ˆë‹¤.

    with conn.cursor() as cur:
        try:
            psycopg2.extras.execute_batch(cur, sql, data_to_dict) # ë°°ì¹˜ ì‚½ì…
            conn.commit()
        except Exception as e:
            conn.rollback() # ì˜¤ë¥˜ ë°œìƒ ì‹œ íŠ¸ëœì­ì…˜ ë¡¤ë°±
            print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise
    logger.info("ğŸ‰ ëª¨ë“  ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    if conn:
        conn.close()

if __name__ == "__main__":
    update_stock_info()