import logging
import pandas as pd
import numpy as np
import psycopg2
from psycopg2 import extras
from pykrx import stock
from datetime import datetime, timedelta
from typing import List, Dict

# ì‹¤ì œ í™˜ê²½ì— ë§ê²Œ DB ì—°ê²° ê´€ë ¨ ëª¨ë“ˆì„ ì„í¬íŠ¸í•´ì•¼ í•©ë‹ˆë‹¤.
from src.fundamental.data_loader.db_util import get_db_connection, setup_database
from src.fundamental.data_loader.config import DB_CONFIG

# --- ë¡œê¹… ì„¤ì • ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def get_all_company_codes(conn) -> List[Dict[str, str]]:
    """
    stock_info í…Œì´ë¸”ì—ì„œ ëª¨ë“  íšŒì‚¬ì˜ ì½”ë“œì™€ ì´ë¦„ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    """
    with conn.cursor() as cur:
        cur.execute("SELECT company_code, company_name FROM stock_info")
        rows = cur.fetchall()
        return [{"company_code": row[0], "company_name": row[1]} for row in rows]


def get_daily_data_with_trading_value(company_list: List[Dict[str, str]]) -> pd.DataFrame:
    """
    ì£¼ì–´ì§„ ëª¨ë“  íšŒì‚¬ì— ëŒ€í•œ ì¼ë´‰ ë°ì´í„°(OHLCV)ì™€ ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜ ê±°ë˜ëŒ€ê¸ˆ ë°ì´í„°ë¥¼ pykrxë¥¼ í†µí•´ ê°€ì ¸ì˜µë‹ˆë‹¤.
    """
    all_company_data = []
    to_date = datetime.now().strftime('%Y%m%d')
    from_date = (datetime.now() - timedelta(days=365 * 3)).strftime('%Y%m%d')

    for company in company_list:
        try:
            df_ohlcv = stock.get_market_ohlcv(from_date, to_date, company['company_code'], 'd')
            if df_ohlcv.empty:
                continue

            df_trading_value = stock.get_market_trading_value_by_date(from_date, to_date, company['company_code'])

            df_foreign_net_buy = df_trading_value[['ì™¸êµ­ì¸í•©ê³„']].reset_index()
            df_foreign_net_buy['ì™¸êµ­ì¸í•©ê³„'] = (df_foreign_net_buy['ì™¸êµ­ì¸í•©ê³„'] / 100_000_000).astype(int)
            df_foreign_net_buy = df_foreign_net_buy.rename(columns={'ë‚ ì§œ': 'candle_date', 'ì™¸êµ­ì¸í•©ê³„': 'foreign_net_buy_amount'})

            df_ohlcv = df_ohlcv.reset_index().rename(columns={'ë‚ ì§œ': 'candle_date'})
            merged_df = pd.merge(df_ohlcv, df_foreign_net_buy, on='candle_date', how='left')

            merged_df['company_code'] = company['company_code']
            merged_df['company_name'] = company['company_name']
            all_company_data.append(merged_df)
            logger.info(f"âœ… {company['company_name']}({company['company_code']}) ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âš ï¸ {company['company_name']}({company['company_code']}) ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")

    if not all_company_data:
        return pd.DataFrame()

    final_df = pd.concat(all_company_data, ignore_index=True)
    final_df = final_df.rename(columns={
        'ì‹œê°€': 'open',
        'ê³ ê°€': 'high',
        'ì €ê°€': 'low',
        'ì¢…ê°€': 'close',
        'ê±°ë˜ëŸ‰': 'volume'
    })

    final_df = final_df[['company_code', 'company_name', 'candle_date', 'open', 'high', 'low', 'close', 'volume', 'foreign_net_buy_amount']]
    return final_df


def save_daily_data_to_db(conn, df: pd.DataFrame):
    """
    ì¼ë³„ ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— UPSERTí•©ë‹ˆë‹¤.
    """
    if df.empty:
        logger.info("ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    logger.info(f"ğŸ’¾ ì´ {len(df)}ê°œì˜ ì¼ë³„ ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥(UPSERT)í•©ë‹ˆë‹¤...")
    df = df.replace({np.nan: None})
    data_to_dict = df.to_dict('records')

    columns = data_to_dict[0].keys()
    cols_str = ", ".join([f'"{col}"' for col in columns])
    placeholders = ", ".join([f"%({col})s" for col in columns])

    update_cols = ['open', 'high', 'low', 'close', 'volume', 'foreign_net_buy_amount']
    update_str = ", ".join([f'"{col}" = EXCLUDED."{col}"' for col in update_cols])
    update_str += ', updated_at = CURRENT_TIMESTAMP'

    sql = f"""
    INSERT INTO stock_day_candles ({cols_str})
    VALUES ({placeholders})
    ON CONFLICT (company_code, candle_date) DO UPDATE SET
        {update_str};
    """

    with conn.cursor() as cur:
        try:
            psycopg2.extras.execute_batch(cur, sql, data_to_dict)
            conn.commit()
            logger.info("ğŸ‰ ëª¨ë“  ì¼ë³„ ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            conn.rollback()
            logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise


def update_stock_daily_data():
    """
    ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹¤í–‰í•˜ì—¬ ì¼ë³„ ì£¼ì‹ ë°ì´í„°ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    """
    conn = None
    try:
        logger.info("ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ì— ì—°ê²°í•©ë‹ˆë‹¤...")
        conn = get_db_connection(DB_CONFIG)

        logger.info("ğŸ› ï¸ `stock_day_candles` í…Œì´ë¸” ìŠ¤í‚¤ë§ˆë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.")
        setup_database(conn, path='src/fundamental/data_loader/sql/stock_day_candles_schema.sql')
        
        logger.info("ğŸ“ˆ `stock_info`ì—ì„œ ëª¨ë“  ì¢…ëª© ì½”ë“œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤...")
        company_list = get_all_company_codes(conn)
        
        if not company_list:
            logger.warning("`stock_info` í…Œì´ë¸”ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. `update_stock_info`ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            return

        logger.info(f"ğŸ“Š ì´ {len(company_list)}ê°œ ì¢…ëª©ì˜ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...")
        final_df = get_daily_data_with_trading_value(company_list)

        save_daily_data_to_db(conn, final_df)

    except Exception as e:
        logger.error(f"âŒ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    finally:
        if conn:
            conn.close()
            logger.info("ğŸ”— ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")


if __name__ == "__main__":
    update_stock_daily_data()