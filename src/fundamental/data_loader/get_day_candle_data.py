import logging
import pandas as pd
import numpy as np
import psycopg2
from psycopg2 import extras
from pykrx import stock
from datetime import datetime
from src.fundamental.data_loader.db_util import get_db_connection, setup_database
from src.fundamental.data_loader.config import DB_CONFIG
from typing import List, Dict, Any
from datetime import timedelta

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def get_all_company_codes(conn) -> List[Dict[str, str]]:
    """
    stock_info í…Œì´ë¸”ì—ì„œ ëª¨ë“  íšŒì‚¬ì˜ ì½”ë“œì™€ ì´ë¦„ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    """
    with conn.cursor() as cur:
        cur.execute("SELECT company_code, company_name FROM stock_info")
        rows = cur.fetchall()
        return [{"company_code": row[0], "company_name": row[1]} for row in rows]

def get_weekly_candle_data(company_list: List[Dict[str, str]]) -> pd.DataFrame:
    """
    ì£¼ì–´ì§„ ëª¨ë“  íšŒì‚¬ì— ëŒ€í•œ ì¼ë´‰ ë°ì´í„°ë¥¼ pykrxë¥¼ í†µí•´ ê°€ì ¸ì˜µë‹ˆë‹¤.
    """
    all_weekly_data = []
    to_date = datetime.now().strftime('%Y%m%d')
    from_date = (datetime.now() - timedelta(days=365*1)).strftime('%Y%m%d')  # ìµœê·¼ 5ë…„ì¹˜ ë°ì´í„°

    for company in company_list:
        try:
            # 'from_date'ë¥¼ ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ì „ì²´ ê¸°ê°„ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
            df = stock.get_market_ohlcv(
                from_date, # 1ë…„
                to_date,
                company['company_code'],
                'd' # ì¼ë´‰ ë°ì´í„°
            )

            if df.empty:
                continue

            df['company_code'] = company['company_code']
            df['company_name'] = company['company_name']
            all_weekly_data.append(df)
            logger.info(f"âœ… {company['company_name']}({company['company_code']}) ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")

        except Exception as e:
            logger.error(f"âš ï¸ {company['company_name']}({company['company_code']}) ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")

    if not all_weekly_data:
        return pd.DataFrame()

    final_df = pd.concat(all_weekly_data)
    final_df = final_df.reset_index()
    final_df = final_df.rename(columns={
        'ë‚ ì§œ': 'candle_date',
        'ì‹œê°€': 'open',
        'ê³ ê°€': 'high',
        'ì €ê°€': 'low',
        'ì¢…ê°€': 'close',
        'ê±°ë˜ëŸ‰': 'volume'
    })

    # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
    final_df = final_df[['company_code', 'company_name', 'candle_date', 'open', 'high', 'low', 'close', 'volume']]
    return final_df

def save_day_data_to_db(conn, df: pd.DataFrame):
    """
    ì¼ë´‰ ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— UPSERTí•©ë‹ˆë‹¤.
    """
    if df.empty:
        logger.info("ì €ì¥í•  ì¼ë´‰ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    logger.info(f"ğŸ’¾ ì´ {len(df)}ê°œì˜ ì¼ë´‰ ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥(UPSERT)í•©ë‹ˆë‹¤...")
    df = df.replace({np.nan: None})
    data_to_dict = df.to_dict('records')

    columns = data_to_dict[0].keys()
    cols_str = ", ".join([f'"{col}"' for col in columns])
    placeholders = ", ".join([f"%({col})s" for col in columns])

    # ON CONFLICT ì‹œ ì—…ë°ì´íŠ¸í•  ì»¬ëŸ¼ë“¤ (ê³ ìœ  í‚¤ ì œì™¸)
    update_cols = ['open', 'high', 'low', 'close', 'volume']
    update_str = ", ".join([f'"{col}" = EXCLUDED."{col}"' for col in update_cols])
    update_str += ', updated_at = CURRENT_TIMESTAMP' # updated_at íƒ€ì„ìŠ¤íƒ¬í”„ ê°±ì‹ 

    sql = f"""
    INSERT INTO stock_day_candles ({cols_str})
    VALUES ({placeholders})
    ON CONFLICT (company_code, candle_date) DO UPDATE SET
        {update_str};
    """

    with conn.cursor() as cur:
        try:
            psycopg2.extras.execute_batch(cur, sql, data_to_dict)
            conn.commit()
            logger.info("ğŸ‰ ëª¨ë“  ì¼ë´‰ ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            conn.rollback()
            logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise

def update_stock_weekly_candles():
    """
    ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹¤í–‰í•˜ì—¬ ì¼ë´‰ ë°ì´í„°ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    """
    conn = None
    try:
        logger.info("ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ì— ì—°ê²°í•©ë‹ˆë‹¤...")
        conn = get_db_connection(DB_CONFIG)

        logger.info("ğŸ› ï¸ `stock_weekly_candles` í…Œì´ë¸” ìŠ¤í‚¤ë§ˆë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.")
        setup_database(conn, path='src/fundamental/data_loader/sql/stock_day_candles_schema.sql')

        logger.info("ğŸ“ˆ `stock_info` í…Œì´ë¸”ì—ì„œ ëª¨ë“  ì¢…ëª© ì½”ë“œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤...")
        company_list = get_all_company_codes(conn)

        if not company_list:
            logger.warning("`stock_info` í…Œì´ë¸”ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. `update_stock_info`ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            return

        logger.info(f"ğŸ“Š ì´ {len(company_list)}ê°œ ì¢…ëª©ì˜ ì£¼ë´‰ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...")
        weekly_data_df = get_weekly_candle_data(company_list)

        save_day_data_to_db(conn, weekly_data_df)

    finally:
        if conn:
            conn.close()
            logger.info("ğŸ”— ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")

if __name__ == "__main__":
    update_stock_weekly_candles()